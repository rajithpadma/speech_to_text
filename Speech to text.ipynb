{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0226bb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'r' to start recording and 's' to stop.\n",
      "Recording started...\n",
      "Recording in progress. Type 's' to stop.\n",
      "Stopping recording...\n",
      "Audio saved to recorded_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajit\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: hi I am Gajala from Washington DC CEO Sonic solutions\n",
      "Model saved to speech_model.h5\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "import speech_recognition as sr\n",
    "from datetime import datetime\n",
    "import os\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "# Function to record audio until user inputs 's' to stop\n",
    "def interactive_recording(samplerate=16000):\n",
    "    print(\"Type 'r' to start recording and 's' to stop.\")\n",
    "    recording_queue = queue.Queue()\n",
    "    is_recording = False\n",
    "    stop_recording = threading.Event()\n",
    "\n",
    "    def audio_callback(indata, frames, time, status):\n",
    "        if status:\n",
    "            print(f\"Error in audio stream: {status}\")\n",
    "            return\n",
    "        recording_queue.put(indata.copy())\n",
    "\n",
    "    def record_audio():\n",
    "        try:\n",
    "            stream = sd.InputStream(samplerate=samplerate, channels=1, dtype='int16', callback=audio_callback)\n",
    "            with stream:\n",
    "                while not stop_recording.is_set():\n",
    "                    pass  # Keep the stream active\n",
    "        except Exception as e:\n",
    "            print(f\"Error during recording: {e}\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            user_input = input(\"Enter 'r' to record or 's' to stop: \").strip().lower()\n",
    "            if user_input == 'r' and not is_recording:\n",
    "                print(\"Recording started...\")\n",
    "                is_recording = True\n",
    "                stop_recording.clear()  # Ensure the stop event is cleared\n",
    "                recording_thread = threading.Thread(target=record_audio)\n",
    "                recording_thread.daemon = True  # Allow the main thread to exit\n",
    "                recording_thread.start()\n",
    "                recording = []  # Initialize/reset the recording list\n",
    "                print(\"Recording in progress. Type 's' to stop.\")\n",
    "\n",
    "            elif user_input == 's' and is_recording:\n",
    "                print(\"Stopping recording...\")\n",
    "                stop_recording.set()  # Signal the recording thread to stop\n",
    "                is_recording = False\n",
    "                # Gather all recorded audio from the queue\n",
    "                while not recording_queue.empty():\n",
    "                    recording.append(recording_queue.get())\n",
    "                if recording:\n",
    "                    combined_audio = np.concatenate(recording, axis=0)\n",
    "                    return combined_audio\n",
    "                else:\n",
    "                    return np.array([], dtype='int16') # Return empty array\n",
    "\n",
    "            elif user_input == 's' and not is_recording:\n",
    "                print(\"No recording to stop. Type 'r' to start recording first.\")\n",
    "\n",
    "            else:\n",
    "                print(\"Invalid input. Use 'r' to record and 's' to stop.\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        if is_recording:\n",
    "            print(\"Keyboard interrupt detected. Stopping recording...\")\n",
    "            stop_recording.set()\n",
    "            while not recording_queue.empty():\n",
    "                recording.append(recording_queue.get())\n",
    "            if recording:\n",
    "                combined_audio = np.concatenate(recording, axis=0)\n",
    "                return combined_audio\n",
    "            else:\n",
    "                return np.array([], dtype='int16')\n",
    "        else:\n",
    "            print(\"No audio recorded. Exiting...\")\n",
    "            return None\n",
    "    finally:\n",
    "        if is_recording:\n",
    "            stop_recording.set() # Ensure the recording thread stops\n",
    "\n",
    "# Function to save audio to a .wav file\n",
    "def save_audio(audio_data, filename, samplerate=16000):\n",
    "    if audio_data.size > 0:  # Check if there is audio data to save\n",
    "        sf.write(filename, audio_data, samplerate, subtype='PCM_16')\n",
    "        print(f\"Audio saved to {filename}\")\n",
    "    else:\n",
    "        print(\"No audio data to save.\")\n",
    "\n",
    "# Function to transcribe audio using a pre-trained model\n",
    "def transcribe_audio(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Error: File not found at {filename}\")\n",
    "        return None\n",
    "\n",
    "    recognizer = sr.Recognizer()\n",
    "    try:\n",
    "        with sr.AudioFile(filename) as source:\n",
    "            audio = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(\"Transcription:\", text)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Speech Recognition could not understand the audio.\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function to save the model\n",
    "def save_model(model, filename):\n",
    "    if filename.endswith('.h5'):\n",
    "        model.save(filename)\n",
    "        print(f\"Model saved to {filename}\")\n",
    "    elif filename.endswith('.pkl'):\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(model, file)\n",
    "        print(f\"Model saved to {filename}\")\n",
    "    else:\n",
    "        print(\"Unsupported file format. Use .h5 or .pkl.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Record audio interactively\n",
    "    audio_data = interactive_recording()\n",
    "\n",
    "    if audio_data is not None and audio_data.size > 0:\n",
    "        # Save the audio to a file\n",
    "        audio_filename = \"recorded_audio.wav\"\n",
    "        save_audio(audio_data, audio_filename)\n",
    "\n",
    "        # Transcribe the audio\n",
    "        transcription = transcribe_audio(audio_filename)\n",
    "\n",
    "        # Example: Using a simple pre-trained model (for demonstration purposes)\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(10, activation='relu', input_shape=(10,)),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        # Save the model\n",
    "        model_filename = \"speech_model.h5\"\n",
    "        save_model(model, model_filename)\n",
    "    elif audio_data is not None:\n",
    "        print(\"No audio data was recorded.\")\n",
    "    else:\n",
    "        print(\"No audio data to process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94337992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
